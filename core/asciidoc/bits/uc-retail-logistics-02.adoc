== Lab {counter:labs}: Track & Trace

In retail you will send your orders to your customer, right? For this a shipment have be created and you should able to follow the shipment (and of course the logistic service partner and your customers too).

=== Step {counter:steps-uc2}: Start the ksqlDB CLI

To start the ksqlDB CLI run the following command:-

[IMPORTANT]
====
[source,subs="attributes"]
----
docker exec -it ksqldb-cli ksql http://ksqldb-server-onprem:8088
----
====


=== Step {counter:steps-uc2}: Inspect a topic\'s contents

To inspect the contents of a topic run the following:-

```
PRINT 'uc_orders' from beginning limit 3;
```

You should see something similar:-

[source,subs="attributes"]
----
ksql> PRINT 'uc_orders' from beginning limit 3;
Key format: JSON or KAFKA_STRING
Value format: JSON or KAFKA_STRING
rowtime: 2021/04/26 12:46:14.856 Z, key: "1", value: {"ORDER_TS": "2021-04-14T11:58:25Z","SHOP":"Otto","PRODUCT":"iPhoneX","ORDER_PLACED":"BERLIN","TOTAL_AMOUNT": 462.11,"CUSTOMER_NAME": "Carsten Muetzlitz"}
rowtime: 2021/04/26 12:46:14.887 Z, key: "2", value: {"ORDER_TS": "2021-04-14T12:58:25Z","SHOP":"Apple","PRODUCT":"MacBookPro13","ORDER_PLACED":"BERLIN","TOTAL_AMOUNT": 3462.11,"CUSTOMER_NAME": "Carsten Muetzlitz"}
rowtime: 2021/04/26 12:46:14.888 Z, key: "3", value: {"ORDER_TS": "2021-04-14T13:58:25Z","SHOP":"Amazon","PRODUCT":"Apple Pencil","ORDER_PLACED":"BERLIN","TOTAL_AMOUNT": 62.11,"CUSTOMER_NAME": "Carsten Muetzlitz"}
Topic printing ceased

----

=== Step {counter:steps-uc2}: Create Orders Stream

Create DDL for order and later for shipments using following query:-

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*CREATE STREAM* orders_stream (
    orderid VARCHAR key, 
    order_ts VARCHAR, 
    shop VARCHAR, 
    product VARCHAR, 
    order_placed VARCHAR, 
    total_amount DOUBLE, 
    customer_name VARCHAR)
  *WITH* (KAFKA_TOPIC='uc_orders',
          VALUE_FORMAT='JSON',
          TIMESTAMP='order_ts',
          TIMESTAMP_FORMAT='yyyy-MM-dd''T''HH:mm:ssX');
----
====

Check your creation with describe and select. 

[source]
----
describe orders_stream;
----

[source]
----
set 'auto.offset.reset'='earliest';
select * from orders_stream emit changes;
----

=== Step {counter:steps-uc2}: Create Shipment Stream

We'll follow the same steps to create the shipments stream:-

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*CREATE STREAM* shipments_stream (
    shipmentid varchar key, 
    shipment_id VARCHAR, 
    shipment_ts VARCHAR, 
    order_id VARCHAR, 
    delivery VARCHAR)
  *WITH* (KAFKA_TOPIC='uc_shipments',
          VALUE_FORMAT='JSON',
          TIMESTAMP='shipment_ts',
          TIMESTAMP_FORMAT='yyyy-MM-dd''T''HH:mm:ssX'); 
----
====

Check your creation with describe and select. 

[source]
----
describe shipments_stream;
----

[source]
----
set 'auto.offset.reset'='earliest';
select * from shipments_stream emit changes;
----

=== Step {counter:steps-uc2}: Create Shipped Order Streams

Let's create the shipped orders stream, joining the orders and shipments streams:-

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*CREATE STREAM* shipped_orders *AS*
  *SELECT* 
    o.orderid AS order_id,
    TIMESTAMPTOSTRING(o.rowtime, 'yyyy-MM-dd HH:mm:ss') *AS* order_ts,
    o.total_amount,
    o.customer_name,
    s.shipment_id,
    TIMESTAMPTOSTRING(s.rowtime, 'yyyy-MM-dd HH:mm:ss') *AS* shipment_ts,
    s.delivery, 
    (s.rowtime - o.rowtime) / 1000 / 60 *AS* ship_time
  *FROM* orders_stream *o* 
    *INNER JOIN* shipments_stream *s*
      *WITHIN* 30 DAYS
      *ON* o.orderid = '"'+s.order_id+'"';
----
====

Check your creation with describe and select. 

[source]
----
describe shipped_orders;
----

[source]
----
set 'auto.offset.reset'='earliest';
select * from shipped_orders emit changes;
----

=== Step {counter:steps-uc2}: Create Shipment Status Stream

We'll follow the same steps to create the shipment status stream:-

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*CREATE STREAM* shipment_statuses_stream (
    shipment_id VARCHAR, 
    status VARCHAR, 
    warehouse VARCHAR)
  *WITH* (KAFKA_TOPIC='uc_shipment_status',
          VALUE_FORMAT='JSON'); 
----
====

Check your creation with describe and select. 

[source]
----
describe shipment_statuses_stream;
----

[source]
----
set 'auto.offset.reset'='earliest';
select * from shipment_statuses_stream emit changes;
----

=== Step {counter:steps-uc2}: Insert data via ksqlDB

You can also try to insert data via `insert statements`

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*INSERT INTO* orders_stream (
    orderid, order_ts, shop, product, order_placed, total_amount, customer_name) 
  *VALUES* ('"10"', '2019-03-29T06:01:18Z', 'Otto', 'iPhoneX','Berlin', 133548.84, 'Mark Mustermann');
*INSERT INTO* shipments_stream (
    shipmentid, shipment_id, shipment_ts, order_id, delivery) 
  *VALUES* ('"ship-ch83360"','ship-ch83360', '2019-03-31T18:13:39Z', '10', 'UPS');
*INSERT INTO* shipment_statuses_stream (
    shipment_id, status, warehouse) 
  *VALUES* ('ship-ch83360', 'in delivery', 'BERLIN');
*INSERT INTO* shipment_statuses_stream (
    shipment_id, status, warehouse) 
  *VALUES* ('ship-ch83360', 'in delivery', 'FRANKFURT');
*INSERT INTO* shipment_statuses_stream (
    shipment_id, status, warehouse) 
  *VALUES* ('ship-ch83360', 'delivered', '@customer');
----
====

See the inserted data:-

[source]
----
set 'auto.offset.reset'='earliest';
select * from shipment_statuses_stream emit changes;
----

=== Step {counter:steps-uc2}: Create stateful Table

In order to access the most up to date information at any given time, let's create a Sateful Table:-

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*CREATE TABLE* shipment_statuses_table *AS*
  *SELECT* 
    shipment_id,
    histogram(status) *AS* status_counts,
    collect_list('{ "status" : "' + status + '"}') *AS* status_list,
    histogram(warehouse) *AS* warehouse_counts,
    collect_list('{ "warehouse" : "' + warehouse + '"}') *AS* warehouse_list
  *FROM* shipment_statuses_stream
  *WHERE* status is not null
  *GROUP BY* shipment_id;
  
----
====

Now you can see the table structure..

[source]
----
describe shipment_statuses_table;
----

To view your tables run the following command:-

[source,subs="quotes,attributes"]
----
SHOW TABLES;
----

=== Step {counter:steps-uc2}: Access inventory via Push Query

Now let's ask ksqlDB what is the status for a specific item in our inventory, via Pull Query:-

[source,subs="quotes,attributes"]
----
select * from shipment_statuses_table where SHIPMENT_ID='ship-ch83360';
----

=== Step {counter:steps-uc2}: Asymmetric join

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*CREATE STREAM* shipments_with_status_stream *AS*
  *SELECT* 
    ep.shipment_id *AS* shipment_id,
    ep.order_id *AS* order_id,
    ps.status_counts *AS* status_counts,
    ps.status_list *AS* status_list,
    ps.warehouse_counts *AS* warehouse_counts,
    ps.warehouse_list *AS* warehouse_list
  *FROM* shipments_stream ep 
    *LEFT JOIN* shipment_statuses_table ps 
      *ON* ep.shipment_id = ps.shipment_id ;
----
====

Now you can see the table structure..

[source]
----
describe shipments_with_status_stream;
----

See the data in the table:-

[source,subs="quotes,attributes"]
----
select * from shipments_with_status_stream EMIT CHANGES;
----

Result seems to be same, but add a new status to shipment ship-ch83360 and you will see stream is not changed

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
*INSERT INTO* shipment_statuses_stream (shipment_id, status, warehouse) *VALUES* ('ship-ch83360', 'post-update', '@attendee');
----
====

You will see no change in the `shipments_with_status_stream` stream

[source,subs="quotes,attributes"]
----
select * from shipments_with_status_stream emit changes;
----

But in table status is seen

[source,subs="quotes,attributes"]
----
select * from shipment_statuses_table where shipment_id='ship-ch83360';
----

Exit the ksqlDB cli 

[IMPORTANT]
====
[source,subs="quotes,attributes"]
----
exit
----
====
